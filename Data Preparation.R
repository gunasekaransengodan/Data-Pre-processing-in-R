#WorkingDirectry Path Setting

getwd()
setwd("<File Path>") #OR Select Files Using 
getwd()

#Load Data from Text File

campaign      <- read.table("<File Path:campaign Data Retrived from Data storage>",header=T,sep="\t")
customers     <- read.table("<File Path:customers info Retrived from Data storage>",header=T,sep="\t")
products      <- read.table("<File Path:Associated products details Retrived from Data storage>",header=T,sep="\t")
transactions  <- read.table("<File Path:transactions Data Retrived from Data storage>",header=T,sep="\t")

#Desctiptive Analysys and Exploring Original Data

str(campaign)
str(customers)
str(products)
str(transactions) #Data.Frame Data Type

#View Data's In File 'V' Caps

View(campaign)
View(customers)
View(products)
View(transactions)

#Check Summery Data 
summary(campaign)
summary(customers)
summary(products)
summary(transactions)

#Check Null Or Missed value from the data

colSums(is.na(campaign))
colSums(is.na(customers))
colSums(is.na(products))
colSums(is.na(transactions)) 

#Load some of frequent used packages to support initial data manipulation task and visualize data 
# for better understanding with all type of data

library(dplyr)
library(ggplot2)
library(reshape2)
library(lubridate)
#----------------------------------------------------------------------------------------------------------------------
#Analysis 1. Based on the transactions, which product category dominates in terms of $amount?
#(Hint: You will need to merge Transactions and Product data sets and then look at Product category)

#Check Top few data for understanding columns and values

head(products)
head(transactions)

#Merge transactions, products file datas

dataRevenue <- merge(x=transactions, y=products, by="Product_Code", all=T)

#Merge Result Dimention and records

dim(dataRevenue)
dim(transactions)
dim(products)

#Sum Result

dataSum <- sum(dataRevenue$Items_Amount)

#Q1 Objective 

dataGroupby <- dataRevenue%>%group_by(Product_Category)%>%summarise(revenue=sum(Items_Number), no_item=sum(Items_Number))

revenueDataUnGroupdataFrame <- dataRevenue%>%filter(Items_Amount>0)%>%group_by(Product_Category)%>%summarise(Count=n(), 
                                                   Percentage_Sum=n()/sum(Items_Amount),
                                                   Total_Sales=sum(Items_Amount), 
                                                   Sales_Percentage = round(Total_Sales/sum(Items_Amount),2),
                                                   Average = mean(Items_Amount),
                                                   Revenue = sum(Items_Number))%>%
                                                   ungroup()%>%arrange(-Total_Sales)%>%mutate(Sales.Contribution_for=rep("Product",7))%>%data.frame()
  

#Total Sales
#Variable - totalSales & Value
#Using Product_Category as id variables

totalSales <- dataRevenue%>%filter(Items_Amount>0)%>%group_by(Product_Category)%>%summarise(totalSales = sum(Items_Amount))%>%melt()

#Per Sales Figure

totalSales$perSales <- round(totalSales$value/sum(dataRevenue$Items_Amount),2)

#View quick Result Summary

View(dataGroupby)
View(revenueDataUnGroupdataFrame)
View(totalSales)

#Order By Value of Revenue to no dominating no#

dataOrderby       <- dataGroupby%>%arrange(desc(revenue))
dataFrameOrderby  <- revenueDataUnGroupdataFrame%>%arrange(desc(Average))
totalSalesOrderBy <- totalSales%>%arrange(desc(value))

#Quick Graphical View to see amount of revenue generated by Each Category(Best Understanding descriptions)

revenueDataPlot <- ggplot(totalSales,aes(x=Product_Category,y=value,fill=Product_Category))

revenueDataPlot + geom_bar(stat="identity",alpha=0.7) +
  labs(x="Product Category", fill="Product Category") +
  geom_text(aes(label=perSales,color=perSales), vjust=-0.3,size=5) +
  theme_classic() + 
  scale_fill_discrete(c=50,h=c(1,360),h.start=50) + 
  guides(color=FALSE) +
  xlab("Product Category")+
  ylab("sales in $") +
  ggtitle("Revenue Generated by each category") +
  scale_y_continuous(breaks = seq(0,35000000,5000000))

#Write solution output data in.csv file

write.csv(revenueDataUnGroupdataFrame,"Revenue generated by product Category.csv", row.names = FALSE)

#Analysys Result
#Answer Prediction - Product Category 'Entertainment' dominates with 40% of total Revenue.  
#----------------------------------------------------------------------------------------------------------------------


#Analysis 2. Perform a suitable age grouping and find out contribution of each of the age group in terms of $ amount spent.
#(Hint: A merge between Customer and Transaction table will be required)

#Merge Tables transactions And customers

dataAgeGroup <- merge(x=transactions,y=customers,by="Card_ID")

#Quick Details Check

str(dataAgeGroup)
summary(dataAgeGroup)
View(dataAgeGroup)

#Try create Age from Available DOB Data, Derive Data and create New Column

dataAgeGroup$Birth_Date <- ymd(dataAgeGroup$Birth_Date)
year<-duration(num=1,units="years")
dataAgeGroup$age=interval(dataAgeGroup$Birth_Date,Sys.Date())/year

#Check Quickly top Records with Age Colum

head(dataAgeGroup$age,100)
tail(dataAgeGroup$age,100)

#Make a Round value to see meaningful Age

dataAgeGroup$age <- round(dataAgeGroup$age)

#Add Age Groups Column with meaningful Break

dataAgeGroup <- arrange(dataAgeGroup,age)
dataAgeGroup$ageGroup <- cut(dataAgeGroup$age,breaks=18)

#Quick Check of New two Columns

View(dataAgeGroup)

#Calculate Expenditures

totalExpenditures <- sum(dataAgeGroup$Items_Amount)

#Check Total

totalExpenditures

#Summarize Age group and Expenditures contribution of each of the age group in terms of $ amount spent

ageDataUnGroupdataFrame <- dataAgeGroup%>%filter(Items_Amount>0)%>%group_by(ageGroup)%>%summarise(Count=n(), 
                                                              Percentage_Count=n()/sum(Items_Amount),
                                                              Total_Contribution=sum(Items_Amount), 
                                                              Contribution_Percentage = round(Total_Contribution/sum(Items_Amount),2),
                                                              Average = mean(Items_Amount),
                                                              Spent = sum(Items_Number))%>%
                                                              ungroup()%>%arrange(-Total_Contribution)%>%data.frame()


totalSpent <- dataAgeGroup%>%filter(Items_Amount>0)%>%group_by(ageGroup)%>%summarise(totalSpent=sum(Items_Amount))%>%melt()

#Quick View

View(totalSpent)
summary(totalSpent)
View(ageDataUnGroupdataFrame)

#Per Sum Amount from total spent and Cumulative Sum 

totalSpent$perTotal <- round(totalSpent$value/totalExpenditures,2)
totalSpent$cumulativePerTotal <- cumsum(totalSpent$perTotal)


#Quick Graphical View to see Expenditures contribution of each of the age group in terms of $ amount spent(Best Understanding descriptions)
AgeDataPlot <- ggplot(totalSpent, aes(x=ageGroup, y=value, fill=ageGroup))
AgeDataPlot + geom_bar(stat="identity",alpha=0.7) +
  labs(x="Age Group in Years", fill="Age Group in Years") +
  geom_text(aes(label=perTotal,color=perTotal), vjust=-0.3,size=5) +
  theme_classic() + 
  scale_fill_discrete(c=50,h=c(1,360),h.start=50) + 
  guides(color=FALSE) +
  xlab("Age Group in Years")+
  ylab("Amount Spent in $") +
  ggtitle("Amount Spent By Different Age groups") +
  scale_y_continuous(breaks = seq(0,15000000,1000000))

#Write solution output data in.csv file

write.csv(ageDataUnGroupdataFrame,"Revenue generated by Age Group.csv", row.names = FALSE)

#Analysys Result
#Answer Prediction - People from age group 45 to 60 spent the maximum and People age less and equal in 35 and 75 spent Less.
#----------------------------------------------------------------------------------------------------------------------

#Analysis 3. Find the response rate to the campaign. Also identify the age group of customers where response rate is high. Is there a consistent trend.
#(Hint: Add age information from customer file to the campaign file, compute response rate by age. This can be done by binning age either in deciles or
#quartiles and seeing if there is a consistent trend)

#Method1:Deciles
#Quick Campaign Exploration

View(campaign)
summary(campaign) #FALSE:5632,TRUE :325  

#Response Rate for executed Campaign in %
#Sum of True & FALSE in Campaign_Responce Column in Summary is 5957

campaignDataPercentage <- campaign%>%group_by(Campaign_Responce)%>%summarise(Count=n(),
                                      Percentage_Count =n() / 5957 * 100)%>%
                                      arrange(-Campaign_Responce)%>%data.frame()

#Identify the age group of customers where response rate is high. Is there a consistent trend.
#Create Age column using DOB

customers$Birth_Date <- ymd(customers$Birth_Date)
year <- duration(num = 1, units = "years")
customers$age = interval(customers$Birth_Date,Sys.Date()) / year
customers$age <- round(customers$age)

#Merge Both Campaign and Customers Table

customersCampaign <- merge(x=campaign, y=customers,by="Card_ID",x.all=T)

#Quick Look to check new age Column

str(customersCampaign)
summary(customersCampaign)

#Add Age Groups Column with meaningful Break

customersCampaign$ageGroup <- cut(customersCampaign$age, breaks = 10)

#Quick Look to check new ageGroup Column

summary(customersCampaign)
str(customersCampaign)

#Find Response Rate to the Campaign as Q3 Objective

customersCampaign$Campaign_Responce <- as.factor(customersCampaign$Campaign_Responce)
customersCampaignResponseTable <- table(customersCampaign$ageGroup,customersCampaign$Campaign_Responce)

customersCampaignResponseTable

#Quick Graphical View to see Response by Age Group for Campaign(Best Understanding descriptions)

str(customersCampaignResponseTable)
responseDataFrame <- as.data.frame(customersCampaignResponseTable)

str(responseDataFrame)

#Assign proper Name for Column

names(responseDataFrame) <- c("Age Group","Response", "Count")
View(responseDataFrame)

customersCampaignResponseRate <- customersCampaignResponseTable[, "TRUE"] / rowSums(customersCampaignResponseTable) * 100

#Quick Look Resonse Rate

str(customersCampaignResponseRate)

responseRateDataFrame <- as.data.frame(customersCampaignResponseRate)

#Assign proper Name for Column

str(responseRateDataFrame)
#names(responseRateDataFrame) <- c("Age Group in Years","Response Rate")

#Write solution output data in.csv file

write.csv(customersCampaignResponseRate,"Response by Age Group.csv", row.names = TRUE)

#Method2
#Other Way considering only 4 Quantile separation graph

Q3 <- merge(x=campaign, y=customers,by="Card_ID", all.x=T) #Card_ID is Unique 'by'

#Add Age Column using DOB

Q3%>%mutate(age=(Sys.Date() - as.Date(Birth_Date)) / 365)

#Quantile Of Age Column

quantile(as.numeric(Q3$age), c(0,2.5,5,7.5,10) / 10)

#Age Group based on Quantile

Q3 <- Q3%>%mutate(quantile=ntile(as.numeric(age),4))

#Binary Dummy variable to observe Cabaign Response based on True, False as 1, 0 Respectively

Q3$Campaign_Responce <- gsub("TRUE",1,Q3$Campaign_Responce)
Q3$Campaign_Responce <- gsub("FALSE",0,Q3$Campaign_Responce)

#Response Rate with Quantile

Q3CampaignResponse <- Q3%>%group_by(quantile)%>%summarise(Response_Rate=sum(as.numeric(Campaign_Responce)/n())*100)

#Add a column to show age group and qualtile range

quantile(round(as.numeric(Q3$age), digits=2), c(0,2.5,5,7.5,10) / 10)

Q3CampaignResponse <- Q3CampaignResponse%>%mutate(Age_Group=c("26.25-38.04","48.04-55.11","55.11-62.51","61-51-110.36"))
Q3CampaignResponse$Age_Group <- as.factor(Q3CampaignResponse$Age_Group)

#Write solution output data in.csv file

write.csv(Q3CampaignResponse,"Response by Age Group Quantile.csv", row.names = FALSE)

campaignDataPlot <- ggplot(Q3CampaignResponse,aes(x=Age_Group,y=Response_Rate,label=round(Response_Rate,digits=2))) +
                    geom_point() + geom_text(vjust=-0.5) 

#Quick Graphical View to see Response

plot(campaignDataPlot)

PlotOutput <- data.frame(Age_Group=Q3CampaignResponse$Age_Group,Response_rate=Q3CampaignResponse$Response_Rate)
plot(PlotOutput)

#Analysys Result

#Method1 
#Answer Prediction (Deciles:10 Age Group range) - Response Rate tp the Capaign is 7.04%
                                          #Highest Response rate within age group is 35 to 43
#File Reference : #Response by Age Group_Edited.ods

#Method2 
#Answer Prediction (Quantile:4 Age Group Range) - Response Rate tp the Capaign is 6.7%
                                                  #Highest Response rate within age group is 26 to 48  

#There is no notable consistent Trend among age groups

#----------------------------------------------------------------------------------------------------------------------

#Analysis 4. Repeat the analysis above with "Tenure" of customer. (Tenure will be 

#defined as the time period between the Date of Registration and 31/12/2002)

#Create Variable for Tenure

customersCampaign$Registration_Date <- ymd(customersCampaign$Registration_Date)

#Take a Format with given Date for objective finding

Date = as.Date("31/12/2002",format="%d/%m/%Y")
year <- duration(num = 1, units = "years")

#Create and Assign Type to Tenure after making Round Value

customersCampaign$Tenure = interval(customersCampaign$Registration_Date,Date) / year
customersCampaign$Tenure <- round(customersCampaign$Tenure)
customersCampaign$Tenure <- as.factor(customersCampaign$Tenure)

#Quick Look value in table

str(customersCampaign)
summary(customersCampaign)
View(customersCampaign)

#Response Rate Calculation 

customersCampaignTenure <- table(customersCampaign$Tenure,customersCampaign$Campaign_Responce)
customersCampaignTenureRate <- customersCampaignTenure[, "TRUE"] / rowSums(customersCampaignTenure) * 100

#Write solution output data in.csv file

write.csv(customersCampaignTenureRate,"Customer Campign Response by Tenure Year.csv", row.names = TRUE)

#Quick Graph Look

plot(customersCampaignTenureRate)

#Analysys Result

#Answer Prediction -  Response Rate shows tenure of 2 year is the highest amoung customers
#There is no notable consistent Trend using tenure

#----------------------------------------------------------------------------------------------------------------------

#Analysis 5. Create a cross tab of response rate between Age(Decile) and Tenure of customers. Do you observe anything?

customersCampaignByAgeTenure <- table(customersCampaign$Tenure,customersCampaign$ageGroup,customersCampaign$Campaign_Responce)
customersCampaignByAgeTenureRate <- customersCampaignByAgeTenure / rowSums(customersCampaignByAgeTenure) *100

#Quick Graph Look

plot(customersCampaignByAgeTenureRate)

customersCampaignByAgeTenureRateToWrite <- as.data.frame(customersCampaignByAgeTenureRate)
names(customersCampaignByAgeTenureRateToWrite) <- c("Tenure Years","Age Group","Response", "Count")

#Write solution output data in.csv file

write.csv(customersCampaignByAgeTenureRateToWrite,"Customer Campign Response by Age & Tenure Year.csv", row.names = TRUE)

#Analysys Result

#Answer Prediction -  Response Rate shows for all tenure from customers of age starting from 43 to 68

#To specifically Rank of top 3 Age Group for Tenrure response's are
#Rank 1 : 52 - 60
#Rank 2 : 43 - 52
#Rank 3 : 60 - 69

#----------------------------------------------------------------------------------------------------------------------

#Analysis 6. Which mode of payment is most popular? Is mode of payment affected by the time of transaction?
#(Hint: Extract hour information from timestamp column by using appropriate date conversion 
#function, based on the hour of the day extracted, you can do an appropriate classification 
#and then look at the cross tab between payment mode and time of day)

#New Naming Customer with Transaction details for below observation check

customersTransactions <- merge(x=transactions,y=customers,by="Card_ID")

#Format allignments and setting specific time to observe changes and details

customersTransactions$Registration_Date <- ymd(customersTransactions$Registration_Date)
Date = as.Date("31/12/2002", format="%d/%m/%Y")

#Tenure column fixing

year <- duration(num =1, units="years")
customersTransactions$Tenure = interval(customersTransactions$Registration_Date,Date) / year
customersTransactions$Tenure <- round(customersTransactions$Tenure)

#Timestamp column and Hour Couln fixing to check Trend for time of dat

customersTransactions$Timestamp <- ymd_hms(customersTransactions$Timestamp)
customersTransactions$hour <- hour(customersTransactions$Timestamp)

#Check the cross tab between payment mode and time of day

customersTransactionsPaymentByTime <- table(customersTransactions$Payment_Method, customersTransactions$hour)
customersTransactionsPaymentByTimeRate <- customersTransactionsPaymentByTime / rowSums(customersTransactionsPaymentByTime) * 100

plot(customersTransactionsPaymentByTimeRate)

#Write solution output data in.csv file

write.csv(customersTransactionsPaymentByTimeRate,"Customer's Prefered Payment mode.csv", row.names = TRUE)

#Cash       : 0.209
#CreditCard : 0.238
#DebitCard  : 0.229

#Analysys Result

#Answer Prediction -  The most popular method of payment is Credit Card. (But difference is small)
# Looks the mode of payment is not affecting  by the time of transaction

#----------------------------------------------------------------------------------------------------------------------
#Analysis 7. Do you think, based on the data, that age and gender has any impact on $amount spent?
#(Hint: You'll need to merge customer and transaction tables appropriately and  then do an age classification, 
#post that you can create a cross tab between gender and age to arrive at an opinion)

#Reuse and assign data frame in different name to use for Q7 Analysys

customersTransactionsByageGender <- dataAgeGroup

# Response Rate Preparation
# Tilde is used to separate the left- and right-hand sides in a model formula

customersTransactionsByageGenderRate <- xtabs(customersTransactionsByageGender$Items_Amount~customersTransactionsByageGender$Gender + customersTransactionsByageGender$ageGroup)
customersTransactionsByageGenderImpact <- customersTransactionsByageGenderRate / rowSums(customersTransactionsByageGenderRate) * 100                                              

plot(customersTransactionsByageGenderImpact)

#Write solution output data in.csv file

write.csv(customersTransactionsByageGenderImpact,"Age and gender impact on amount spent.csv", row.names = TRUE) 

#Analysys Result

# Answer Prediction -  People of Age group 45 to 60 in Both Gender spending Most. 
# No specific significant impact only becasue of gender.

#----------------------------------------------------------------------------------------------------------------------
#Analysis 8. Produce a histogram for "tenure of a customer" separately for male and female customers.

customersTransactions$Registration_Date <- ymd(customersTransactions$Registration_Date)
Date = as.Date("31/12/2002", format="%d/%m/%Y")
year <- duration(num =1, units ="years")
customersTransactions$Tenure = interval(customersTransactions$Registration_Date,Date) / year
customersTransactions$Tenure <- round(customersTransactions$Tenure,2)

par(mfrow = c(2,1))


tenureofaCustomerPlotMale <- ggplot(customersTransactions%>%filter(Gender=="M"), aes(x=Tenure, color=Gender,fill=Gender)) +
                         geom_histogram(bins=10,position = "dodge",alpha="0.5") +
                         theme_classic() + xlab("Tenure of Customer in Years") +
                         ylab("Number of Customers") + ggtitle("Tenure of Customer (Male)")  

tenureofaCustomerPlotFemale <- ggplot(customersTransactions%>%filter(Gender=="F"), aes(x=Tenure, color=Gender,fill=Gender)) +
  geom_histogram(bins=10,position = "dodge",alpha="0.5") +
  theme_classic() + xlab("Tenure of Customer in Years") +
  ylab("Number of Customers") + ggtitle("Tenure of Customer(Female)")  

library(gridExtra)

grid.arrange(tenureofaCustomerPlotMale,tenureofaCustomerPlotFemale, nrow =1, ncol=2)

#Analysys Result

# Answer Prediction -  Plot Code added

#----------------------------------------------------------------------------------------------------------------------

